{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "606bb0d0-b22f-4e09-a9d3-c7b0f8b156e9",
   "metadata": {},
   "source": [
    "## Loading Dataset as an input x — Defining Dataset Class\n",
    "**The paths to the files** are as follows:\n",
    "- 'dataset/y_test.csv'\n",
    "- 'dataset/y_train.csv'\n",
    "- 'dataset/Automotive_Ethernet_with_Attack_original_10_17_20_04_test.pcap'\n",
    "- 'dataset/Automotive_Ethernet_with_Attack_original_10_17_19_50_training.pcap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95929b71-f573-4658-b3ff-16fa04ab59d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scapy==2.4.4 in /home/sallysooo/miniforge3/lib/python3.11/site-packages (2.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install scapy==2.4.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b579345-b2a4-4e91-b71f-9b8921cb1f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing the pcap file...: 1203737it [00:00, 1664432.82it/s]\n",
      "Parsing the pcap file...: 791611it [00:00, 1739585.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 2 distinct timestamps. -> 1 correction(s).\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scapy.utils import RawPcapReader\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import skew\n",
    "\n",
    "class TimeseriesGenerator:\n",
    "    pass # Implemented below\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, df: pd.DataFrame, trim_etc_protocols=True):\n",
    "        if trim_etc_protocols:\n",
    "            self.df = df[df['ProtocolType'] != ''].copy()\n",
    "        else:\n",
    "            self.df = df\n",
    "        assert self.df['abstime'].is_monotonic_increasing\n",
    "        assert self.df['monotime'].is_monotonic_increasing\n",
    "\n",
    "    @classmethod\n",
    "    def _load_towids_dataset(cls, path_pcap, usec_unit, path_csv=None, **kwargs):\n",
    "        # assert scapy.__version__ == '2.4.4', 'scapy version mismatch.'\n",
    "\n",
    "        reader = RawPcapReader(str(path_pcap))\n",
    "        list_output = list()\n",
    "        for idx, (payload, metadata) in tqdm(enumerate(reader), desc='Parsing the pcap file...'):\n",
    "            sec, usec, wirelen, caplen = metadata\n",
    "            list_output.append((sec, usec, wirelen, caplen, payload))\n",
    "        df_pcap = pd.DataFrame(list_output, columns=['sec', 'usec', 'wirelen', 'caplen', 'payload'])\n",
    "\n",
    "        if path_csv:\n",
    "            df_label = pd.read_csv(path_csv, header=None, names=['idx', 'label', 'y_desc'])\n",
    "            assert df_pcap.shape[0] == df_label.shape[0], \\\n",
    "                f'Record count mismatch. {df_pcap.shape=}, {df_label.shape=}'\n",
    "            assert (df_label['idx'].diff().bfill() == 1).all(), 'Field `idx` does not increase sequentially.'\n",
    "            df_label['y'] = df_label['label'].map({'Normal': 0, 'Abnormal': 1})\n",
    "        else:\n",
    "            df_label = pd.DataFrame(index=df_pcap.index)\n",
    "            df_label['y'] = 0\n",
    "            df_label['y_desc'] = 'Normal'\n",
    "        abstime = pd.to_datetime(df_pcap['sec'], unit='s') + pd.to_timedelta(df_pcap['usec'], unit=usec_unit)\n",
    "        dupcounts = abstime.duplicated(keep=False).sum()\n",
    "\n",
    "        if dupcounts > 0:\n",
    "            print(f'There were {dupcounts} distinct timestamps.', end=' ')\n",
    "            for _ in range(100):\n",
    "                duplicated = abstime.duplicated()\n",
    "                if duplicated.sum() == 0:\n",
    "                    break\n",
    "                abstime[duplicated] += pd.Timedelta(milliseconds=1)\n",
    "            else:\n",
    "                raise ValueError('Something went wrong.')\n",
    "            print(f'-> {_} correction(s).')\n",
    "\n",
    "        monotime = (abstime - abstime.min()).dt.total_seconds()\n",
    "        df_pcap['payload'] = df_pcap['payload'].map(lambda x: np.frombuffer(x, dtype='uint8'))\n",
    "\n",
    "        df: pd.DataFrame = pd.concat([\n",
    "            abstime.rename('abstime'),\n",
    "            monotime.rename('monotime'),\n",
    "            df_pcap[['wirelen', 'caplen', 'payload']],\n",
    "            df_label[['y', 'y_desc']]\n",
    "        ], axis=1)\n",
    "\n",
    "        df = df.sort_values('abstime')\n",
    "        assert df['abstime'].is_monotonic_increasing\n",
    "        assert df['monotime'].is_monotonic_increasing\n",
    "\n",
    "        # Protocol specification\n",
    "        df['ProtocolType'] = ''\n",
    "        df.loc[df['wirelen'] == 60, 'ProtocolType'] = 'UDP'\n",
    "        df.loc[df['wirelen'].isin([68, 90]), 'ProtocolType'] = 'PTP'\n",
    "        df.loc[df['wirelen'].isin([82, 434]), 'ProtocolType'] = 'AVTP'\n",
    "        # special treatment\n",
    "        df.loc[df['y_desc'] == 'P_I', 'ProtocolType'] = 'PTP'\n",
    "\n",
    "        return cls(df, **kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def towids_train(cls, **kwargs):\n",
    "        return cls._load_towids_dataset(\n",
    "            Path('dataset/Automotive_Ethernet_with_Attack_original_10_17_19_50_training.pcap'),\n",
    "            'ns',\n",
    "            Path('dataset/y_train.csv'),\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def towids_test(cls, **kwargs):\n",
    "        return cls._load_towids_dataset(\n",
    "            Path('dataset/Automotive_Ethernet_with_Attack_original_10_17_20_04_test.pcap'),\n",
    "            'ns',\n",
    "            Path('dataset/y_test.csv'),\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    def do_label(self, window_size) -> np.ndarray:\n",
    "        y = self.df.rolling(window=window_size)['y'].max().dropna().astype('int32').values\n",
    "        assert isinstance(y, np.ndarray)\n",
    "        return y\n",
    "\n",
    "    def trim(self, time_start=None, time_end=None, is_absolute=None):\n",
    "        assert is_absolute is not None\n",
    "        monotime_min = self.df['monotime'].min()\n",
    "        monotime_max = self.df['monotime'].max()\n",
    "\n",
    "        if time_start is not None:\n",
    "            if is_absolute is False:\n",
    "                time_start = monotime_min + time_start\n",
    "            assert monotime_min < time_start\n",
    "        else:\n",
    "            time_start = monotime_min\n",
    "\n",
    "        if time_end is not None:\n",
    "            if is_absolute is False:\n",
    "                time_end = monotime_max - time_end\n",
    "            assert time_end < monotime_max\n",
    "        else:\n",
    "            time_end = monotime_max\n",
    "\n",
    "        df = self.df.query(f'{time_start} <= monotime <= {time_end}').copy()\n",
    "        # print('Before [{} ~ {}] / Required [{} ~ {}] / After [{} ~ {}]'.format(\n",
    "        #     monotime_min, monotime_max,\n",
    "        #     time_start, time_end,\n",
    "        #     df['monotime'].min(), df['monotime'].max()\n",
    "        # ))\n",
    "        return Dataset(df)\n",
    "        \n",
    "    # Feature generator 1 (FG1)\n",
    "    def do_fg1_transition_matrix(self, window_size=2048) -> np.array:\n",
    "        # When the number of collected packets is n, a numpy array of shape = (n, 3, 3) should be the output\n",
    "        df = self.df\n",
    "        # proto_types = sorted(df['ProtocolType'].unique()) # ex) ['AVTP', 'PTP', 'UDP']\n",
    "        idx = {'AVTP': 0, 'PTP': 1, 'UDP': 2} # ex) {'AVTP': 0, 'PTP': 1, 'UDP': 2}\n",
    "        N = len(idx) # 3\n",
    "\n",
    "        # 1. ProtocolType sequence -> integer index\n",
    "        proto_seq = df['ProtocolType'].map(idx).values # [2, 0, 0, 1, 2]\n",
    "\n",
    "        # 2. generate T\n",
    "        def seq_to_transition_matrix(seq):\n",
    "          T = np.zeros((N, N), dtype=np.float32)\n",
    "          for i in range(len(seq) - 1):\n",
    "            a, b = seq[i], seq[i+1]\n",
    "            T[a, b] += 1\n",
    "          T /= (len(seq)-1) # normalization\n",
    "          return T\n",
    "\n",
    "        if len(proto_seq) < window_size:\n",
    "          raise ValueError(f\"Insufficient data length ({len(proto_seq)}) for window_size {window_size}\")\n",
    "\n",
    "        # checkpoint\n",
    "        print(\"Data shape:\", proto_seq.shape)\n",
    "        print(\"Window size:\", window_size)\n",
    "\n",
    "        # 3. sliding window using TimeseriesGenerator\n",
    "        generator = TimeseriesGenerator(proto_seq, length=window_size, sampling_rate=1, stride=1, batch_size=1, shuffle=False)\n",
    "\n",
    "        print(\"Generator length:\", len(generator))\n",
    "        # if len(generator) == 0:\n",
    "        #   print(\"Warning: Generator is empty! Check window_size and data length.\")\n",
    "        #   return np.zeros((0, N, N))\n",
    "\n",
    "        result = []\n",
    "        for X, _ in generator:\n",
    "          seq = X[0] # (window_size, )\n",
    "          T = seq_to_transition_matrix(seq)\n",
    "          result.append(T)\n",
    "\n",
    "        return np.stack(result) # (num_windows, N, N)\n",
    "\n",
    "\n",
    "    # Feature generator 2 (FG2)\n",
    "    def do_fg2_payload(self, window_size=2048, byte_start=0x22, byte_end=0x22 + 9) -> np.array:\n",
    "        '''\n",
    "        - The paper's strategy is to take 9 bytes from the 0x22th byte for the payload loaded in each packet.  \n",
    "        - Short payloads should be padded with 0x00.\n",
    "        - When the number of collected packets is n, a numpy array with shape = (n, 9) should be generated. \n",
    "        - FG2 does not need to apply TimeseriesGenerator.\n",
    "        '''\n",
    "        assert byte_start < byte_end\n",
    "        num_bytes = byte_end - byte_start # 9\n",
    "\n",
    "        payloads = []\n",
    "        for arr in self.df['payload'].values:\n",
    "          segment = np.zeros(num_bytes, dtype=np.uint8) # [0, 0, 0, ..., 0]\n",
    "          arr_len = len(arr)\n",
    "          for i in range(num_bytes): # 9\n",
    "            if byte_start + i < arr_len:\n",
    "              segment[i] = arr[byte_start + i]\n",
    "          payloads.append(segment / 255.0)\n",
    "\n",
    "        return np.array(payloads) # (n ,9)\n",
    "\n",
    "\n",
    "    # Feature generator 3 (FG3)\n",
    "    def do_fg3_statistics(self, window_size=2048, methods=('mean', 'std', 'skew')) -> np.array:\n",
    "        '''\n",
    "        - When the number of collected packets is n, a numpy array of shape=(n, 3, 3) should be generated.\n",
    "        - The <feature normalization strategy> described at the bottom right of page 5 of the paper must be implemented.\n",
    "        '''\n",
    "        df = self.df\n",
    "        # proto_types = sorted(df['ProtocolType'].unique()) # ex) ['AVTP', 'PTP', 'UDP']\n",
    "        idx = {'AVTP': 0, 'PTP': 1, 'UDP': 2} # ex) {'AVTP': 0, 'PTP': 1, 'UDP': 2}\n",
    "        N = len(idx) # ex) 3\n",
    "\n",
    "        monotime = df['monotime'].values\n",
    "        protos = df['ProtocolType'].map(idx).values\n",
    "\n",
    "        # each window is constructed as [window_size * 2]\n",
    "        generator = TimeseriesGenerator(\n",
    "            np.stack([monotime, protos], axis=1), # (n, 2)\n",
    "            length = window_size,\n",
    "            sampling_rate = 1,\n",
    "            stride = 1,\n",
    "            batch_size = 1,\n",
    "            shuffle = False\n",
    "            )\n",
    "\n",
    "        # checkpoint\n",
    "        print(\"Data shape:\", np.stack([monotime, protos], axis=1).shape)\n",
    "        print(\"Window size:\", window_size)\n",
    "\n",
    "        result = []\n",
    "        for X, _ in generator:\n",
    "          x_window = X[0] # (window_size, 2)\n",
    "          t = x_window[:, 0] # first column of 'monotime' [1.0, 1.2, 1.3, 2.0, ...]\n",
    "          p = x_window[:, 1].astype(int) # second column of 'protos(protocol index)' [0, 0, 1, 0]\n",
    "\n",
    "          stat_matrix = np.full((N, 3), 1e+7, dtype=np.float32) # Initialize default value to 1e+7\n",
    "\n",
    "          for i in range(N):\n",
    "            t_i = t[p == i] # time sequence of the ith protocol / t : [1.0, 1.2, 1.3, 2.0, ...] / p==i : [True, True, False, True, ...] / t[p==i] : [1.0, 1.2, 2.0] => select protocol by this workflow\n",
    "            if len(t_i) >= 2:\n",
    "                diffs = np.diff(t_i)\n",
    "                mean_val = np.mean(diffs)\n",
    "                stat_matrix[i, 0] = mean_val\n",
    "\n",
    "                if len(diffs) >= 2:\n",
    "                    std_val = np.std(diffs)\n",
    "                    stat_matrix[i, 1] = std_val\n",
    "                if len(diffs) >= 3:\n",
    "                    skew_val = np.abs(skew(diffs))\n",
    "                    stat_matrix[i, 2] = skew_val\n",
    "            \n",
    "          stat_matrix = np.where(stat_matrix == 0, 1e-7, stat_matrix)\n",
    "          stat_matrix = np.log10(stat_matrix)\n",
    "\n",
    "          result.append(stat_matrix)\n",
    "\n",
    "        return np.stack(result) # (num_windows, N, 3)\n",
    "\n",
    "dataset_train = Dataset.towids_train()\n",
    "dataset_test = Dataset.towids_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba0c3ea-b32b-477f-8f71-fdd2e72126cf",
   "metadata": {},
   "source": [
    "### 1. Train file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85121eeb-338c-4acb-a0ce-b1fa9a9c53bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstime</th>\n",
       "      <th>monotime</th>\n",
       "      <th>wirelen</th>\n",
       "      <th>caplen</th>\n",
       "      <th>payload</th>\n",
       "      <th>y</th>\n",
       "      <th>y_desc</th>\n",
       "      <th>ProtocolType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-09-12 09:51:04.715221</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>434</td>\n",
       "      <td>434</td>\n",
       "      <td>[145, 239, 0, 0, 254, 0, 0, 252, 112, 0, 0, 3,...</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>AVTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-09-12 09:51:04.715245</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>434</td>\n",
       "      <td>434</td>\n",
       "      <td>[145, 239, 0, 0, 254, 0, 0, 252, 112, 0, 0, 3,...</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>AVTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-09-12 09:51:04.715326</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>434</td>\n",
       "      <td>434</td>\n",
       "      <td>[145, 239, 0, 0, 254, 0, 0, 252, 112, 0, 0, 3,...</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>AVTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-09-12 09:51:04.715450</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>434</td>\n",
       "      <td>434</td>\n",
       "      <td>[145, 239, 0, 0, 254, 0, 0, 252, 112, 0, 0, 3,...</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>AVTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-09-12 09:51:04.715559</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>434</td>\n",
       "      <td>434</td>\n",
       "      <td>[145, 239, 0, 0, 254, 0, 0, 252, 112, 0, 0, 3,...</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>AVTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203732</th>\n",
       "      <td>2020-09-12 10:00:16.911784</td>\n",
       "      <td>552.196563</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>[220, 166, 50, 94, 72, 71, 220, 166, 50, 93, 2...</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>UDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203733</th>\n",
       "      <td>2020-09-12 10:00:16.912231</td>\n",
       "      <td>552.197010</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>[220, 166, 50, 94, 72, 71, 220, 166, 50, 93, 2...</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>UDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203734</th>\n",
       "      <td>2020-09-12 10:00:16.912686</td>\n",
       "      <td>552.197465</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>[220, 166, 50, 94, 72, 71, 220, 166, 50, 93, 2...</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>UDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203735</th>\n",
       "      <td>2020-09-12 10:00:16.913172</td>\n",
       "      <td>552.197951</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>[220, 166, 50, 94, 72, 71, 220, 166, 50, 93, 2...</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>UDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203736</th>\n",
       "      <td>2020-09-12 10:00:16.915384</td>\n",
       "      <td>552.200163</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>[220, 166, 50, 94, 72, 71, 220, 166, 50, 93, 2...</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>UDP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1203334 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           abstime    monotime  wirelen  caplen  \\\n",
       "0       2020-09-12 09:51:04.715221    0.000000      434     434   \n",
       "1       2020-09-12 09:51:04.715245    0.000024      434     434   \n",
       "2       2020-09-12 09:51:04.715326    0.000105      434     434   \n",
       "3       2020-09-12 09:51:04.715450    0.000229      434     434   \n",
       "4       2020-09-12 09:51:04.715559    0.000338      434     434   \n",
       "...                            ...         ...      ...     ...   \n",
       "1203732 2020-09-12 10:00:16.911784  552.196563       60      60   \n",
       "1203733 2020-09-12 10:00:16.912231  552.197010       60      60   \n",
       "1203734 2020-09-12 10:00:16.912686  552.197465       60      60   \n",
       "1203735 2020-09-12 10:00:16.913172  552.197951       60      60   \n",
       "1203736 2020-09-12 10:00:16.915384  552.200163       60      60   \n",
       "\n",
       "                                                   payload  y  y_desc  \\\n",
       "0        [145, 239, 0, 0, 254, 0, 0, 252, 112, 0, 0, 3,...  0  Normal   \n",
       "1        [145, 239, 0, 0, 254, 0, 0, 252, 112, 0, 0, 3,...  0  Normal   \n",
       "2        [145, 239, 0, 0, 254, 0, 0, 252, 112, 0, 0, 3,...  0  Normal   \n",
       "3        [145, 239, 0, 0, 254, 0, 0, 252, 112, 0, 0, 3,...  0  Normal   \n",
       "4        [145, 239, 0, 0, 254, 0, 0, 252, 112, 0, 0, 3,...  0  Normal   \n",
       "...                                                    ... ..     ...   \n",
       "1203732  [220, 166, 50, 94, 72, 71, 220, 166, 50, 93, 2...  0  Normal   \n",
       "1203733  [220, 166, 50, 94, 72, 71, 220, 166, 50, 93, 2...  0  Normal   \n",
       "1203734  [220, 166, 50, 94, 72, 71, 220, 166, 50, 93, 2...  0  Normal   \n",
       "1203735  [220, 166, 50, 94, 72, 71, 220, 166, 50, 93, 2...  0  Normal   \n",
       "1203736  [220, 166, 50, 94, 72, 71, 220, 166, 50, 93, 2...  0  Normal   \n",
       "\n",
       "        ProtocolType  \n",
       "0               AVTP  \n",
       "1               AVTP  \n",
       "2               AVTP  \n",
       "3               AVTP  \n",
       "4               AVTP  \n",
       "...              ...  \n",
       "1203732          UDP  \n",
       "1203733          UDP  \n",
       "1203734          UDP  \n",
       "1203735          UDP  \n",
       "1203736          UDP  \n",
       "\n",
       "[1203334 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtocolType\n",
      "UDP     846647\n",
      "AVTP    287086\n",
      "PTP      69601\n",
      "Name: count, dtype: int64\n",
      "y_desc\n",
      "Normal    954509\n",
      "C_D        85466\n",
      "P_I        64635\n",
      "F_I        35112\n",
      "M_F        33765\n",
      "C_R        29847\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "display(dataset_train.df)\n",
    "print(dataset_train.df['ProtocolType'].value_counts())\n",
    "print(dataset_train.df['y_desc'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fe8162-9d98-4b7b-8c3d-7da730636cad",
   "metadata": {},
   "source": [
    "### 2. Test file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a725fedd-2f30-4173-879d-e908dd9ad5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstime</th>\n",
       "      <th>monotime</th>\n",
       "      <th>wirelen</th>\n",
       "      <th>caplen</th>\n",
       "      <th>payload</th>\n",
       "      <th>y</th>\n",
       "      <th>y_desc</th>\n",
       "      <th>ProtocolType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-09-12 10:02:59.795192</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>434</td>\n",
       "      <td>434</td>\n",
       "      <td>[145, 239, 0, 0, 254, 0, 0, 252, 112, 0, 0, 3,...</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>AVTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-09-12 10:02:59.810189</td>\n",
       "      <td>0.014997</td>\n",
       "      <td>434</td>\n",
       "      <td>434</td>\n",
       "      <td>[145, 239, 0, 0, 254, 0, 0, 252, 112, 0, 0, 3,...</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>AVTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-09-12 10:02:59.810205</td>\n",
       "      <td>0.015013</td>\n",
       "      <td>434</td>\n",
       "      <td>434</td>\n",
       "      <td>[145, 239, 0, 0, 254, 0, 0, 252, 112, 0, 0, 3,...</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>AVTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-09-12 10:02:59.810295</td>\n",
       "      <td>0.015103</td>\n",
       "      <td>434</td>\n",
       "      <td>434</td>\n",
       "      <td>[145, 239, 0, 0, 254, 0, 0, 252, 112, 0, 0, 3,...</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>AVTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-09-12 10:02:59.810414</td>\n",
       "      <td>0.015222</td>\n",
       "      <td>434</td>\n",
       "      <td>434</td>\n",
       "      <td>[145, 239, 0, 0, 254, 0, 0, 252, 112, 0, 0, 3,...</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>AVTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791606</th>\n",
       "      <td>2020-09-12 10:09:36.422031</td>\n",
       "      <td>396.626839</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>[220, 166, 50, 94, 72, 71, 220, 166, 50, 93, 2...</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>UDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791607</th>\n",
       "      <td>2020-09-12 10:09:36.422535</td>\n",
       "      <td>396.627343</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>[220, 166, 50, 94, 72, 71, 220, 166, 50, 93, 2...</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>UDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791608</th>\n",
       "      <td>2020-09-12 10:09:36.422997</td>\n",
       "      <td>396.627805</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>[220, 166, 50, 94, 72, 71, 220, 166, 50, 93, 2...</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>UDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791609</th>\n",
       "      <td>2020-09-12 10:09:36.423462</td>\n",
       "      <td>396.628270</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>[220, 166, 50, 94, 72, 71, 220, 166, 50, 93, 2...</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>UDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791610</th>\n",
       "      <td>2020-09-12 10:09:36.423838</td>\n",
       "      <td>396.628646</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>[220, 166, 50, 94, 72, 71, 220, 166, 50, 93, 2...</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>UDP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>791324 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          abstime    monotime  wirelen  caplen  \\\n",
       "0      2020-09-12 10:02:59.795192    0.000000      434     434   \n",
       "1      2020-09-12 10:02:59.810189    0.014997      434     434   \n",
       "2      2020-09-12 10:02:59.810205    0.015013      434     434   \n",
       "3      2020-09-12 10:02:59.810295    0.015103      434     434   \n",
       "4      2020-09-12 10:02:59.810414    0.015222      434     434   \n",
       "...                           ...         ...      ...     ...   \n",
       "791606 2020-09-12 10:09:36.422031  396.626839       60      60   \n",
       "791607 2020-09-12 10:09:36.422535  396.627343       60      60   \n",
       "791608 2020-09-12 10:09:36.422997  396.627805       60      60   \n",
       "791609 2020-09-12 10:09:36.423462  396.628270       60      60   \n",
       "791610 2020-09-12 10:09:36.423838  396.628646       60      60   \n",
       "\n",
       "                                                  payload  y  y_desc  \\\n",
       "0       [145, 239, 0, 0, 254, 0, 0, 252, 112, 0, 0, 3,...  0  Normal   \n",
       "1       [145, 239, 0, 0, 254, 0, 0, 252, 112, 0, 0, 3,...  0  Normal   \n",
       "2       [145, 239, 0, 0, 254, 0, 0, 252, 112, 0, 0, 3,...  0  Normal   \n",
       "3       [145, 239, 0, 0, 254, 0, 0, 252, 112, 0, 0, 3,...  0  Normal   \n",
       "4       [145, 239, 0, 0, 254, 0, 0, 252, 112, 0, 0, 3,...  0  Normal   \n",
       "...                                                   ... ..     ...   \n",
       "791606  [220, 166, 50, 94, 72, 71, 220, 166, 50, 93, 2...  0  Normal   \n",
       "791607  [220, 166, 50, 94, 72, 71, 220, 166, 50, 93, 2...  0  Normal   \n",
       "791608  [220, 166, 50, 94, 72, 71, 220, 166, 50, 93, 2...  0  Normal   \n",
       "791609  [220, 166, 50, 94, 72, 71, 220, 166, 50, 93, 2...  0  Normal   \n",
       "791610  [220, 166, 50, 94, 72, 71, 220, 166, 50, 93, 2...  0  Normal   \n",
       "\n",
       "       ProtocolType  \n",
       "0              AVTP  \n",
       "1              AVTP  \n",
       "2              AVTP  \n",
       "3              AVTP  \n",
       "4              AVTP  \n",
       "...             ...  \n",
       "791606          UDP  \n",
       "791607          UDP  \n",
       "791608          UDP  \n",
       "791609          UDP  \n",
       "791610          UDP  \n",
       "\n",
       "[791324 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtocolType\n",
      "UDP     563731\n",
      "AVTP    198013\n",
      "PTP      29580\n",
      "Name: count, dtype: int64\n",
      "y_desc\n",
      "Normal    660490\n",
      "C_D        41203\n",
      "C_R        29847\n",
      "P_I        26013\n",
      "F_I        16962\n",
      "M_F        16809\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "display(dataset_test.df)\n",
    "print(dataset_test.df['ProtocolType'].value_counts())\n",
    "print(dataset_test.df['y_desc'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff753878-a533-4a22-b13d-b462f423a464",
   "metadata": {},
   "source": [
    "- Create train/validation/test sets by dividing the two packet dump datasets (dataset_train, dataset_test) into different time ranges.\n",
    "- Organize the number of malicious traffic (intrusion) and normal traffic (benign) in these sets into a table as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61327a86-842a-463e-a1db-f4ce6a769f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>y</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>Time range</th>\n",
       "      <th>Benign</th>\n",
       "      <th>Intrusion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Packet dump</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Packet dump 1</th>\n",
       "      <td>Train</td>\n",
       "      <td>[5.00, 60.00]</td>\n",
       "      <td>97,715</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Packet dump 1</th>\n",
       "      <td>Validation</td>\n",
       "      <td>[60.00, 71.11]</td>\n",
       "      <td>19,606</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Packet dump 1</th>\n",
       "      <td>Test</td>\n",
       "      <td>[71.11, 547.20]</td>\n",
       "      <td>819,586</td>\n",
       "      <td>248,080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Packet dump 2</th>\n",
       "      <td>Train</td>\n",
       "      <td>[5.00, 80.00]</td>\n",
       "      <td>130,520</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Packet dump 2</th>\n",
       "      <td>Validation</td>\n",
       "      <td>[80.00, 91.88]</td>\n",
       "      <td>19,943</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Packet dump 2</th>\n",
       "      <td>Test</td>\n",
       "      <td>[91.89, 391.63]</td>\n",
       "      <td>496,151</td>\n",
       "      <td>129,226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "y                 Purpose       Time range   Benign Intrusion\n",
       "Packet dump                                                  \n",
       "Packet dump 1       Train    [5.00, 60.00]   97,715         0\n",
       "Packet dump 1  Validation   [60.00, 71.11]   19,606         0\n",
       "Packet dump 1        Test  [71.11, 547.20]  819,586   248,080\n",
       "Packet dump 2       Train    [5.00, 80.00]  130,520         0\n",
       "Packet dump 2  Validation   [80.00, 91.88]   19,943         0\n",
       "Packet dump 2        Test  [91.89, 391.63]  496,151   129,226"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Arguments to be passed to the do function: \n",
    "# [dataset, purpose, start time, end time, whether to remove the last 5 seconds of noise]\n",
    "args = [\n",
    "    [dataset_train, 'Train', 5, 60, False],\n",
    "    [dataset_train, 'Validation', 60, 71.11, False],\n",
    "    [dataset_train, 'Test', 71.11, None, True],\n",
    "    [dataset_test, 'Train', 5, 80, False],\n",
    "    [dataset_test, 'Validation', 80, 91.88, False],\n",
    "    [dataset_test, 'Test', 91.89, None, True],\n",
    "]\n",
    "\n",
    "def do(dataset, purpose, time_start, time_end, trim_last_5sec):\n",
    "    name = 'Packet dump 1' if dataset is dataset_train else 'Packet dump 2'\n",
    "\n",
    "    dataset = dataset.trim(time_start, time_end, is_absolute=True) # slice [time_start, time_end] part only in the entire dataset\n",
    "    if trim_last_5sec: # Remove noise remaining after the data collection step\n",
    "        dataset = dataset.trim(time_end=5, is_absolute=False)\n",
    "        time_end = dataset.df['monotime'].max() # Since 'time_end' has changed after removing noise, update it again with the actual maximum time\n",
    "    a = dataset.df['y'].value_counts() \n",
    "    a.name = name \n",
    "    a['Purpose'] = purpose \n",
    "    a['Time range'] = '[{:.2f}, {:.2f}]'.format(time_start, time_end)\n",
    "    a = a.rename({0: 'Benign', 1: 'Intrusion'}) # 0 as benign, 1 as intrusion\n",
    "    a = a.reindex(['Purpose', 'Time range', 'Benign', 'Intrusion'], fill_value=0)\n",
    "    return a, dataset\n",
    "\n",
    "\n",
    "list_output = list()\n",
    "list_dataset_sub = list() ######### From here, you can retrieve the Dataset instance as needed.\n",
    "for arg in args:\n",
    "    output, dataset_sub = do(*arg)\n",
    "    list_output.append(output)\n",
    "    list_dataset_sub.append(dataset_sub)\n",
    "\n",
    "df = pd.DataFrame(list_output)\n",
    "df.index.name = 'Packet dump'\n",
    "df[['Benign', 'Intrusion']] = df[['Benign', 'Intrusion']].map('{:,}'.format)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0d70b4-0c82-4082-9436-216ec3dd8fa7",
   "metadata": {},
   "source": [
    "### TimeseriesGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a259981-78a0-4feb-a167-b0a761f79363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class TimeseriesGenerator:\n",
    "    def __init__(self, data, length, sampling_rate=1, stride=1,\n",
    "                 start_index=0, end_index=None,\n",
    "                 shuffle=False, reverse=False, batch_size=128, label=None):\n",
    "        self.data = data\n",
    "        self.length = length\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.stride = stride\n",
    "        self.start_index = start_index + length\n",
    "        if end_index is None:\n",
    "            end_index = len(data)\n",
    "        self.end_index = end_index\n",
    "        self.shuffle = shuffle\n",
    "        self.reverse = reverse\n",
    "        self.batch_size = batch_size\n",
    "        self.label = label if label is None else np.array(label)\n",
    "        if self.start_index > self.end_index:\n",
    "            raise ValueError(\n",
    "                \"`start_index+length=%i > end_index=%i` \"\n",
    "                \"is disallowed, as no part of the sequence \"\n",
    "                \"would be left to be used as current step.\"\n",
    "                % (self.start_index, self.end_index)\n",
    "            )\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.end_index - self.start_index + self.batch_size * self.stride) // (self.batch_size * self.stride)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        rows = self.__index_to_row__(index)\n",
    "        samples, y = self.__compile_batch__(rows)\n",
    "        return samples, y\n",
    "\n",
    "    def __iter__(self):\n",
    "        for i in range(len(self)):\n",
    "            yield self[i]\n",
    "    \n",
    "    def __index_to_row__(self, index):  # Returns a list of rows that will compose a given batch (index). len(rows) is equal to the batch size.\n",
    "        if self.shuffle:\n",
    "            rows = np.random.randint(self.start_index, self.end_index + 1, size=self.batch_size)\n",
    "        else:\n",
    "            i = self.start_index + self.batch_size * self.stride * index\n",
    "            rows = np.arange(i, min(i + self.batch_size * self.stride, self.end_index + 1), self.stride)\n",
    "        return rows\n",
    "\n",
    "    def __compile_batch__(self, rows):  # Generate time series features for each given row.\n",
    "        samples = np.array([self.data[row - self.length: row: self.sampling_rate] for row in rows])\n",
    "        if self.reverse:\n",
    "            samples = samples[:, ::-1, ...]\n",
    "        if self.length == 1:\n",
    "            samples = np.squeeze(samples)\n",
    "\n",
    "        if self.label is None:\n",
    "            return samples, samples\n",
    "        else:\n",
    "            return samples, self.label[rows - self.length]\n",
    "\n",
    "    @property\n",
    "    def output_shape(self):\n",
    "        x, y = self[0]\n",
    "        return x.shape, y.shape\n",
    "\n",
    "    @property\n",
    "    def num_samples(self):\n",
    "        count = 0\n",
    "        for x, y in self:\n",
    "            count += x.shape[0]\n",
    "        return count\n",
    "\n",
    "    def __str__(self):\n",
    "        return '<TimeseriesGenerator data.shape={} / num_batches={:,} / output_shape={}>'.format(\n",
    "            self.data.shape, len(self), self.output_shape,\n",
    "        )\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3381419c-28bd-45c4-bc75-dbb30e1adc41",
   "metadata": {},
   "source": [
    "### Define new Dataset Class \n",
    "- Converting the shape of each FG1-3, to match the dimension as an input value of the Autoencoder model afterwards\n",
    "    - x = (T, P, S)\n",
    "\n",
    "- dataset[i][0] → ((9,), (2048, 9), (9,))\n",
    "- dataset[i][1] → ((9,), (2048, 9), (9,)) ⇒ x == y since it's an autoencoder model\n",
    "- dataloader[i][0] → ((b, 9), (b, 2048, 9), (b, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fc85be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "195c7a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 is avaiable\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"{device} is avaiable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06a9c06-46d6-413e-a98a-bf020ac975af",
   "metadata": {},
   "source": [
    "- New AEGenerator with sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e799fc6c-1732-49c2-825c-54dfd84ee500",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AEGenerator(Dataset):\n",
    "    def __init__(self, T, P, S, window_size=2048, stride=1, sampling_rate=1, shuffle=False, reverse=False): \n",
    "        '''\n",
    "        T : nparray (n, 3, 3) window 단위\n",
    "        P : nparray (m, 9) packet 단위\n",
    "        S : nparray (n, 3, 3) window 단위\n",
    "\n",
    "        window_size : P sliding window 크기 (default : 2048)\n",
    "        stride : sliding window stride (default : 1)\n",
    "        sampling_rate : window 내 sample 간 간격\n",
    "        shuffle : window의 index 순서를 랜덤화할지 여부\n",
    "        reverse : window 내부 순서를 뒤집을지 여부\n",
    "        '''\n",
    "        self.T = T\n",
    "        self.P = P\n",
    "        self.S = S\n",
    "        self.n = T.shape[0]\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.shuffle = shuffle\n",
    "        self.reverse = reverse\n",
    "\n",
    "        '''\n",
    "        P 데이터에서 window 끝의 위치 index 리스트를 생성\n",
    "        - window 끝 index = window_size 이상 위치부터 sliding 시작\n",
    "        - stride 단위로 이동\n",
    "        - T, S 데이터 수에 맞게 index list 조정    \n",
    "        '''\n",
    "        # index list\n",
    "        self.indices = np.arange(window_size, len(P) + 1, stride)\n",
    "        if len(self.indices) > len(T):\n",
    "            self.indices = self.indices[:len(T)] # T, S 크기에 맞춤\n",
    "        \n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "        \n",
    "    \n",
    "    def __len__(self): # index list 길이 = 총 샘플 수\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, index): # 하나의 샘플(x, y)를 리턴\n",
    "        idx = self.indices[index] # idx : 현재 window의 끝 index\n",
    "        \n",
    "        # T, S : (3,3) → (9,) flatten\n",
    "        t = torch.from_numpy(self.T[index].astype('float32')).flatten()\n",
    "        s = torch.from_numpy(self.S[index].astype('float32')).flatten()\n",
    "        \n",
    "        # P window\n",
    "        start_idx = max(0, idx - self.window_size)\n",
    "        end_idx = idx\n",
    "        p_window = self.P[start_idx : end_idx : self.sampling_rate]\n",
    "\n",
    "        if self.reverse:\n",
    "            p_window = p_window[::-1]\n",
    "\n",
    "        # zero padding\n",
    "        if p_window.shape[0] < self.window_size:\n",
    "            pad_size = self.window_size - p_window.shape[0]\n",
    "            padding = np.zeros((pad_size, self.P.shape[1]), dtype=np.float32)\n",
    "            p_window = np.vstack((padding, p_window))\n",
    "\n",
    "        # 최종 window를 torch tensor로 변환\n",
    "        p = torch.from_numpy(p_window.astype('float32'))\n",
    "\n",
    "        x = y = (t, p, s)\n",
    "        \n",
    "        return x, y\n",
    "\n",
    "    def __iter__(self):\n",
    "        for i in range(len(self)):\n",
    "            yield self[i]\n",
    "\n",
    "    @property\n",
    "    def output_shape(self):\n",
    "        x, y = self[0]\n",
    "        t, p, s = x\n",
    "        return (t.shape, p.shape, s.shape)\n",
    "\n",
    "    @property\n",
    "    def num_samples(self): # 총 샘플 수 반환\n",
    "        return len(self)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'<AEGenerator num_samples={self.num_samples} / output_shape={self.output_shape}>'\n",
    "\n",
    "    def __reper__(self):\n",
    "        return self.__str__()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0898728f-62ed-4630-b427-8e1a87fedc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (97715,)\n",
      "Window size: 2048\n",
      "Generator length: 95668\n",
      "FG1 original shape: (95668, 3, 3)\n",
      "\n",
      "FG2 original shape: (97715, 9)\n",
      "\n",
      "Data shape: (97715, 2)\n",
      "Window size: 2048\n",
      "FG3 original shape: (95668, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "original_dataset = list_dataset_sub[0] # 'train' part in dataset_train\n",
    "T = original_dataset.do_fg1_transition_matrix()\n",
    "print(\"FG1 original shape:\", T.shape)\n",
    "print()\n",
    "P = original_dataset.do_fg2_payload()\n",
    "print(\"FG2 original shape:\", P.shape)\n",
    "print()\n",
    "S = original_dataset.do_fg3_statistics()\n",
    "print(\"FG3 original shape:\", S.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aab019e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = AEGenerator(T, P, S, window_size=2048, stride=1)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=False) # n = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13003453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T shape: torch.Size([32, 9])\n",
      "P shape: torch.Size([32, 2048, 9])\n",
      "S shape: torch.Size([32, 9])\n",
      "first T: tensor([1.9052e-01, 4.8852e-04, 5.8134e-02, 4.8852e-04, 0.0000e+00, 5.3737e-03,\n",
      "        5.8134e-02, 5.3737e-03, 6.8149e-01])\n",
      "first P shape: torch.Size([2048, 9])\n",
      "first S: tensor([-2.6514, -2.1638,  0.5255, -0.9898, -1.4139,  0.1699, -3.1195, -3.1355,\n",
      "         0.4396])\n",
      "window size: 2048\n",
      "Zero padding rows in first sample: 2\n"
     ]
    }
   ],
   "source": [
    "for x, _ in dataloader:\n",
    "    t, p, s = x\n",
    "    print(f'T shape: {t.shape}') # (32, 9)\n",
    "    print(f'P shape: {p.shape}') # (32, 2048, 9)\n",
    "    print(f'S shape: {s.shape}') # (32, 9)\n",
    "    assert t.shape[0] == p.shape[0] == s.shape[0], \"T, P, S must have same number of samples!\"\n",
    "    print(f'first T:', t[0])\n",
    "    print(f'first P shape:', p[0].shape)\n",
    "    print(f'first S:', s[0])\n",
    "\n",
    "    window_size = p.shape[1] # save window_size \n",
    "    print(f'window size: {window_size}')\n",
    "\n",
    "    zero_pad_rows = (p[0].sum(axis=1) == 0).sum().item()\n",
    "    print(f\"Zero padding rows in first sample: {zero_pad_rows}\")    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f08afb6",
   "metadata": {},
   "source": [
    "- So as above, currently the shape of the elements in input tuple x is as below:\n",
    "    - t : (b, 9)\n",
    "    - p : (b, 2048, 9)\n",
    "    - s : (b, 9)\n",
    "- Encoder Architecture in the paper:\n",
    "    - T : Flatten -> Dense(64) -> Dense(64)\n",
    "    - P : Seperable Conv1D -> ... (n layers: depends on w) -> Seperable Conv1D -> Seperable Conv1D(576)\n",
    "    - S : Flatten -> Dense(64) -> Dense(64)\n",
    "    - latent vector h : 704 = 64 + 64 + 576\n",
    "- Decoder Architecture in the paper:\n",
    "    - latent space h(704) has 3 independent network : T', P', S'\n",
    "    - T', S' : Dense(64) -> Dense(64) -> Dense(9)\n",
    "    - P' : Transposed SeperableConv1D n layers (last output's channel=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd11bd0",
   "metadata": {},
   "source": [
    "- Pytorch doesn't directly afford SeperableConv1d...\n",
    "    - let's implement in w/ depthwise + pointwise!\n",
    "    - depthwise : apply convolution independently for each channel (groups=input_c)\n",
    "    - pointwise : channel mizing using 1*1 conv\n",
    "- Original P.shape = (b, 2048, 9) — 2048 sequence length, 9 channel for each step\n",
    "    - But PyTorch Conv1D is channel-first format = (b, channel, seq_len)\n",
    "    - So we use permute() function to convert the format : (b, 2048, 9) → (b, 9, 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cadc87c-cd54-4a6a-97f3-c7466a8d7e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeparableConv1d(nn.Module):\n",
    "    def __init__(self, input_c, output_c, kernel_size, **kwargs):\n",
    "        super().__init__()\n",
    "        self.depthwise = nn.Conv1d(input_c, input_c, kernel_size, groups=input_c, **kwargs)\n",
    "        self.pointwise = nn.Conv1d(input_c, output_c, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x) \n",
    "        x = self.pointwise(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ddf6837",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeparableConvTranspose1d(nn.Module):\n",
    "    def __init__(self, input_c, output_c, kernel_size, **kwargs):\n",
    "        super().__init__()\n",
    "        self.depthwise = nn.ConvTranspose1d(input_c, input_c, kernel_size, groups=input_c, **kwargs)\n",
    "        self.pointwise = nn.ConvTranspose1d(input_c, output_c, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016a1c4d-a24f-4759-b837-1645a6c0d7f7",
   "metadata": {},
   "source": [
    "- Dynamic calculation of number of layers\n",
    "  - w : window_size (ex. 2048)\n",
    "  - while w > 10: num_p_layers += 1, w//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24ef2102-9320-47b0-9bdc-577f40f0134f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_num_p_layers(input_length, min_length=10):\n",
    "    num_layers = 0\n",
    "    while input_length > min_length:\n",
    "        input_length //= 2\n",
    "        num_layers += 1\n",
    "    return num_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bc835c0-54a2-4796-bafa-f634684dbf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "7\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(calculate_num_p_layers(2048))  # 8\n",
    "print(calculate_num_p_layers(1024))  # 7\n",
    "print(calculate_num_p_layers(512))   # 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9174c4-385c-4561-ba4d-18ba43b390d6",
   "metadata": {},
   "source": [
    "- 1에서 몇 번이나 2배씩 길이를 늘려야 기존 window_size에 도달할지 계산해보자. (window_size=2048인 경우, 몇 번이나 2배씩 길이를 늘려야 2048에 도달?)\n",
    "- 1 → 2 → 4 → 8 → 16 → 32 → 64 → 128 → 256 → 512 → 1024 → 2048\n",
    "  - 2^n = window_size\n",
    "  - n = log2(window_size)\n",
    "- 따라서 window_size=2048이면 log2(2048)=11으로 11번 doubling이 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5282c6b-db1d-4135-9f95-e234960a21fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def calculate_upsampling_steps(window_size):\n",
    "    log2_ws = math.log2(window_size)\n",
    "    if not log2_ws.is_integer(): # 2의 배수가 아니면 예외처리\n",
    "        raise ValueError(f\"window_size {window_size} must be a power of 2.\")\n",
    "    return int(log2_ws)  # ex: 2048 → 11, 1024 → 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd60102a-002c-4d17-ba4d-95a366b44dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, window_size=2048):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 1. Encoder \n",
    "        self.t_fc1 = nn.Linear(9, 64)\n",
    "        self.t_fc2 = nn.Linear(64, 64)\n",
    "\n",
    "        self.s_fc1 = nn.Linear(9, 64)\n",
    "        self.s_fc2 = nn.Linear(64, 64)\n",
    "\n",
    "        num_p_layers = calculate_num_p_layers(window_size)\n",
    "        p_layers = []\n",
    "        in_ch = 9\n",
    "        for i in range(num_p_layers):\n",
    "            out_ch = 64 if i < num_p_layers - 1 else 576\n",
    "            p_layers.append(SeparableConv1d(in_ch, out_ch, kernel_size=3, padding=1))\n",
    "            in_ch = out_ch\n",
    "        self.p_layers = nn.ModuleList(p_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        t, p, s = x\n",
    "\n",
    "        # 1. Encoder\n",
    "        t = F.relu(self.t_fc1(t))\n",
    "        t = F.relu(self.t_fc2(t))\n",
    "\n",
    "        s = F.relu(self.s_fc1(s))\n",
    "        s = F.relu(self.s_fc2(s))\n",
    "        \n",
    "        '''\n",
    "        for self.p_layers = SeparableConv1D layer\n",
    "        each layer : (b, in_ch, seq_len) -> (b, out_ch, seq_len) + add ReLU activation function\n",
    "        ex) (b, 9, 2048) → relu → (b, 64, 2048) → maxpool → (b, 64, 1024) → relu & maxpool → (b, 64, 512) ... → (b, 128, 512) \n",
    "        - 각 layer 마다 seq_len이 절반으로 감소: 2048 → 1024 → 512 → 256 → 128 → 64 → 32 → 16 ← (8번 Pooling)\n",
    "        - 각 layer 마다 channel 수를 점점 키워서 576 만들기: 9 → 32 → 64 → 128 → 256 → ... → 576\n",
    "        '''\n",
    "        # p : (b, 2048, 9)\n",
    "        p = p.permute(0, 2, 1) # (b, 9, 2048) : (batch, channel, length)\n",
    "        for layer in self.p_layers[:-1]:\n",
    "            p = F.relu(layer(p)) # target is C / same length\n",
    "            p = F.max_pool1d(p, 2) # shorten length 1/2 by maxpool\n",
    "        p = self.p_layers[-1](p) # (b, 576, 16)\n",
    "        p = F.adaptive_max_pool1d(p, 1).squeeze(2)  # latent vector (b, 576) : output length = 1\n",
    "\n",
    "        # latent vector\n",
    "        h = torch.cat([t, p, s], dim=1) # (b, 704)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09013af2-3497-4768-8c82-d046fa9d0a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, window_size=2048):\n",
    "        super().__init__()\n",
    "        # 2. Decoder \n",
    "        self.t_dec_fc1 = nn.Linear(704, 64)\n",
    "        self.t_dec_fc2 = nn.Linear(64, 64)\n",
    "        self.t_dec_fc3 = nn.Linear(64, 9)\n",
    "\n",
    "        self.s_dec_fc1 = nn.Linear(704, 64)\n",
    "        self.s_dec_fc2 = nn.Linear(64, 64)\n",
    "        self.s_dec_fc3 = nn.Linear(64, 9)\n",
    "\n",
    "        num_upsample_layers = calculate_upsampling_steps(window_size)\n",
    "        \n",
    "        self.p_dec_layers = nn.ModuleList()\n",
    "        in_ch = 704\n",
    "        for i in range(num_upsample_layers):\n",
    "            out_ch = 64\n",
    "            self.p_dec_layers.append(SeparableConvTranspose1d(in_ch, out_ch, kernel_size=3, padding=1))\n",
    "            in_ch = out_ch\n",
    "        # last layer : channel 64 -> 9\n",
    "        self.p_output_layer = SeparableConvTranspose1d(64, 9, kernel_size=3, padding=1)\n",
    "\n",
    "        \n",
    "    def forward(self, h):\n",
    "        # 2. Decoder\n",
    "        t = F.relu(self.t_dec_fc1(h))\n",
    "        t = F.relu(self.t_dec_fc2(t))\n",
    "        t = self.t_dec_fc3(t)\n",
    "\n",
    "        s = F.relu(self.s_dec_fc1(h))\n",
    "        s = F.relu(self.s_dec_fc2(s))\n",
    "        s = self.s_dec_fc3(s)\n",
    "\n",
    "        '''\n",
    "        - unsqueeze(2) : add new dimension as (b, 704) -> (b, 704, 1)\n",
    "        - upsampling: 16 → 2048 requires 7 upsampling steps: 1 → 2 → 4 → ... → 128 → 256 → 512 → 1024 → 2048\n",
    "        \n",
    "        Latent vector (b, 704)\n",
    "         ↓ unsqueeze → (b, 704, 1)\n",
    "         ↓ ConvTranspose1d: 704 → 64\n",
    "         ↓ interpolate (2× length) → (b, 64, 2)\n",
    "         ↓ ConvTranspose1d: 64 → 64\n",
    "         ↓ interpolate → (b, 64, 4)\n",
    "         ↓ ...\n",
    "         ↓ Final ConvTranspose1d: 64 → 9\n",
    "         ↓ (b, 9, 2048)\n",
    "         ↓ permute → (b, 2048, 9)\n",
    "\n",
    "        '''\n",
    "        p = h.unsqueeze(2) # (b, 704) -> (b, 704, 1)\n",
    "        for layer in self.p_dec_layers:\n",
    "            p = F.relu(layer(p))\n",
    "            p = F.interpolate(p, scale_factor=2, mode='nearest') # upsample : double the length\n",
    "            \n",
    "        p = self.p_output_layer(p) # final channel 64 -> 9 : (b, 9, 2048)\n",
    "        p = p.permute(0, 2, 1) # (b, 2048, 9)\n",
    "\n",
    "        return t, p, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80fa8614-e320-4ffd-9762-ac1a0a02f194",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, window_size=2048):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = Encoder(window_size)\n",
    "        self.decoder = Decoder(window_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        return self.decoder(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "129c59ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder().to(device)\n",
    "# encoder = autoencoder.encoder\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d849e014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (encoder): Encoder(\n",
       "    (t_fc1): Linear(in_features=9, out_features=64, bias=True)\n",
       "    (t_fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (s_fc1): Linear(in_features=9, out_features=64, bias=True)\n",
       "    (s_fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (p_layers): ModuleList(\n",
       "      (0): SeparableConv1d(\n",
       "        (depthwise): Conv1d(9, 9, kernel_size=(3,), stride=(1,), padding=(1,), groups=9)\n",
       "        (pointwise): Conv1d(9, 64, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (1-6): 6 x SeparableConv1d(\n",
       "        (depthwise): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), groups=64)\n",
       "        (pointwise): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (7): SeparableConv1d(\n",
       "        (depthwise): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), groups=64)\n",
       "        (pointwise): Conv1d(64, 576, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (t_dec_fc1): Linear(in_features=704, out_features=64, bias=True)\n",
       "    (t_dec_fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (t_dec_fc3): Linear(in_features=64, out_features=9, bias=True)\n",
       "    (s_dec_fc1): Linear(in_features=704, out_features=64, bias=True)\n",
       "    (s_dec_fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (s_dec_fc3): Linear(in_features=64, out_features=9, bias=True)\n",
       "    (p_dec_layers): ModuleList(\n",
       "      (0): SeparableConvTranspose1d(\n",
       "        (depthwise): ConvTranspose1d(704, 704, kernel_size=(3,), stride=(1,), padding=(1,), groups=704)\n",
       "        (pointwise): ConvTranspose1d(704, 64, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (1-10): 10 x SeparableConvTranspose1d(\n",
       "        (depthwise): ConvTranspose1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), groups=64)\n",
       "        (pointwise): ConvTranspose1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (p_output_layer): SeparableConvTranspose1d(\n",
       "      (depthwise): ConvTranspose1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), groups=64)\n",
       "      (pointwise): ConvTranspose1d(64, 9, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7250609d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=0: 100%|█| 2990/2990 [00:16<00:00, 176.01it/s, loss_AE=193, loss_p=0.061, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.064549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=1: 100%|█| 2990/2990 [00:16<00:00, 182.07it/s, loss_AE=193, loss_p=0.061, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.064522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=2: 100%|█| 2990/2990 [00:16<00:00, 182.18it/s, loss_AE=193, loss_p=0.061, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.064442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=3: 100%|█| 2990/2990 [00:16<00:00, 182.87it/s, loss_AE=192, loss_p=0.061, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.064279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=4: 100%|█| 2990/2990 [00:16<00:00, 181.55it/s, loss_AE=191, loss_p=0.061, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=5: 100%|█| 2990/2990 [00:16<00:00, 182.37it/s, loss_AE=190, loss_p=0.061, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=6: 100%|█| 2990/2990 [00:16<00:00, 181.60it/s, loss_AE=190, loss_p=0.061, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=7: 100%|█| 2990/2990 [00:16<00:00, 180.23it/s, loss_AE=190, loss_p=0.061, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=8: 100%|█| 2990/2990 [00:16<00:00, 181.18it/s, loss_AE=190, loss_p=0.061, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=9: 100%|█| 2990/2990 [00:17<00:00, 174.94it/s, loss_AE=190, loss_p=0.061, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=10: 100%|█| 2990/2990 [00:17<00:00, 175.13it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=11: 100%|█| 2990/2990 [00:16<00:00, 178.68it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=12: 100%|█| 2990/2990 [00:16<00:00, 175.93it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=13: 100%|█| 2990/2990 [00:16<00:00, 178.57it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=14: 100%|█| 2990/2990 [00:16<00:00, 180.33it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=15: 100%|█| 2990/2990 [00:16<00:00, 176.92it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=16: 100%|█| 2990/2990 [00:16<00:00, 176.42it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=17: 100%|█| 2990/2990 [00:16<00:00, 177.25it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=18: 100%|█| 2990/2990 [00:16<00:00, 176.01it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=19: 100%|█| 2990/2990 [00:16<00:00, 176.24it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=20: 100%|█| 2990/2990 [00:16<00:00, 179.88it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=21: 100%|█| 2990/2990 [00:16<00:00, 177.10it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=22: 100%|█| 2990/2990 [00:16<00:00, 180.70it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=23: 100%|█| 2990/2990 [00:16<00:00, 176.22it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=24: 100%|█| 2990/2990 [00:17<00:00, 175.85it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=25: 100%|█| 2990/2990 [00:16<00:00, 176.92it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=26: 100%|█| 2990/2990 [00:16<00:00, 179.41it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=27: 100%|█| 2990/2990 [00:17<00:00, 173.17it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=28: 100%|█| 2990/2990 [00:17<00:00, 170.26it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=29: 100%|█| 2990/2990 [00:16<00:00, 180.50it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=30: 100%|█| 2990/2990 [00:16<00:00, 181.75it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=31: 100%|█| 2990/2990 [00:16<00:00, 178.46it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=32: 100%|█| 2990/2990 [00:16<00:00, 181.05it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=33: 100%|█| 2990/2990 [00:17<00:00, 175.77it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=34: 100%|█| 2990/2990 [00:17<00:00, 173.28it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=35: 100%|█| 2990/2990 [00:16<00:00, 176.61it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=36: 100%|█| 2990/2990 [00:16<00:00, 178.68it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=37: 100%|█| 2990/2990 [00:16<00:00, 179.76it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=38: 100%|█| 2990/2990 [00:16<00:00, 180.02it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=39: 100%|█| 2990/2990 [00:16<00:00, 180.69it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=40: 100%|█| 2990/2990 [00:16<00:00, 181.64it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=41: 100%|█| 2990/2990 [00:16<00:00, 180.29it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=42: 100%|█| 2990/2990 [00:16<00:00, 176.65it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=43: 100%|█| 2990/2990 [00:16<00:00, 176.20it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=44: 100%|█| 2990/2990 [00:16<00:00, 176.80it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=45: 100%|█| 2990/2990 [00:16<00:00, 178.05it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=46: 100%|█| 2990/2990 [00:16<00:00, 177.57it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=47: 100%|█| 2990/2990 [00:16<00:00, 178.70it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=48: 100%|█| 2990/2990 [00:16<00:00, 177.13it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=49: 100%|█| 2990/2990 [00:16<00:00, 178.41it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=50: 100%|█| 2990/2990 [00:17<00:00, 173.78it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=51: 100%|█| 2990/2990 [00:17<00:00, 171.46it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=52: 100%|█| 2990/2990 [00:16<00:00, 181.67it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=53: 100%|█| 2990/2990 [00:17<00:00, 174.57it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=54: 100%|█| 2990/2990 [00:17<00:00, 174.73it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=55: 100%|█| 2990/2990 [00:16<00:00, 179.39it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=56: 100%|█| 2990/2990 [00:16<00:00, 177.78it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=57: 100%|█| 2990/2990 [00:16<00:00, 176.58it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=58: 100%|█| 2990/2990 [00:16<00:00, 179.48it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=59: 100%|█| 2990/2990 [00:16<00:00, 181.35it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=60: 100%|█| 2990/2990 [00:16<00:00, 176.74it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=61: 100%|█| 2990/2990 [00:16<00:00, 176.60it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=62: 100%|█| 2990/2990 [00:17<00:00, 174.68it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=63: 100%|█| 2990/2990 [00:16<00:00, 177.47it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=64: 100%|█| 2990/2990 [00:17<00:00, 175.69it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=65: 100%|█| 2990/2990 [00:16<00:00, 176.61it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=66: 100%|█| 2990/2990 [00:16<00:00, 178.24it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=67: 100%|█| 2990/2990 [00:17<00:00, 170.95it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=68: 100%|█| 2990/2990 [00:17<00:00, 171.10it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=69: 100%|█| 2990/2990 [00:17<00:00, 171.71it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=70: 100%|█| 2990/2990 [00:17<00:00, 168.07it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=71: 100%|█| 2990/2990 [00:18<00:00, 165.96it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=72: 100%|█| 2990/2990 [00:29<00:00, 102.44it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=73: 100%|█| 2990/2990 [00:23<00:00, 127.28it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=74: 100%|█| 2990/2990 [00:17<00:00, 167.18it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=75: 100%|█| 2990/2990 [00:17<00:00, 167.74it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=76: 100%|█| 2990/2990 [00:17<00:00, 170.40it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=77: 100%|█| 2990/2990 [00:17<00:00, 170.85it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=78: 100%|█| 2990/2990 [00:17<00:00, 173.22it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=79: 100%|█| 2990/2990 [00:17<00:00, 172.06it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=80: 100%|█| 2990/2990 [00:17<00:00, 174.42it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=81: 100%|█| 2990/2990 [00:17<00:00, 173.28it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=82: 100%|█| 2990/2990 [00:17<00:00, 170.80it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=83: 100%|█| 2990/2990 [00:17<00:00, 168.19it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=84: 100%|█| 2990/2990 [00:17<00:00, 169.72it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=85: 100%|█| 2990/2990 [00:17<00:00, 172.03it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=86: 100%|█| 2990/2990 [00:16<00:00, 180.58it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=87: 100%|█| 2990/2990 [00:16<00:00, 177.12it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=88: 100%|█| 2990/2990 [00:16<00:00, 176.14it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=89: 100%|█| 2990/2990 [00:17<00:00, 175.44it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=90: 100%|█| 2990/2990 [00:17<00:00, 174.35it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=91: 100%|█| 2990/2990 [00:17<00:00, 174.16it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=92: 100%|█| 2990/2990 [00:17<00:00, 174.14it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=93: 100%|█| 2990/2990 [00:17<00:00, 175.34it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=94: 100%|█| 2990/2990 [00:17<00:00, 174.08it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=95: 100%|█| 2990/2990 [00:16<00:00, 176.27it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=96: 100%|█| 2990/2990 [00:16<00:00, 180.34it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=97: 100%|█| 2990/2990 [00:16<00:00, 180.22it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=98: 100%|█| 2990/2990 [00:16<00:00, 176.09it/s, loss_AE=190, loss_p=0.061,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=99: 100%|█| 2990/2990 [00:16<00:00, 176.53it/s, loss_AE=190, loss_p=0.061,"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.063563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "epoch1 = 100 # 논문에서는 20이지만 일단 작은 수로 잘 돌아가는지 테스트\n",
    "for epoch in range(epoch1):\n",
    "    loss_AE = 0.0              # loss값 누적할 변수 초기화\n",
    "    pb = tqdm(dataloader, desc=f'{epoch=}')\n",
    "    for x, _ in pb:\n",
    "        t, p, s = (item.to(device) for item in x) \n",
    "\n",
    "        optimizer.zero_grad()       # 이전 배치에서 계산된 기울기 초기화\n",
    "        t_hat, p_hat, s_hat = model((t, p, s))\n",
    "        # print(f't : {t.shape} | p : {p.shape} | s : {s.shape}')\n",
    "        # print(f't_hat : {t_hat.shape} | p_hat : {p_hat.shape} | s_hat : {s_hat.shape}')\n",
    "        # loss = ((t - t_hat)**2 + (p - p_hat)**2 + (s - s_hat)**2).mean() # MSE\n",
    "        \n",
    "        # T loss\n",
    "        loss_t = F.mse_loss(t_hat, t, reduction='mean')  \n",
    "        # print(loss_t)\n",
    "        # P loss\n",
    "        loss_p = F.mse_loss(p_hat, p, reduction='mean')\n",
    "        # print(loss_p)\n",
    "        # S loss\n",
    "        loss_s = F.mse_loss(s_hat, s, reduction='mean')\n",
    "        # print(loss_s)\n",
    "\n",
    "        # loss 합\n",
    "        loss = loss_t + loss_p + loss_s     \n",
    "        # print(loss)\n",
    "\n",
    "        loss.backward() \n",
    "        optimizer.step() \n",
    "        loss_AE += loss.item() # batch의 loss값을 누적해 epoch 전체 loss를 계산\n",
    "\n",
    "        pb.set_postfix(loss_t=loss_t.item(), loss_p=loss_p.item(), loss_s=loss_s.item(), loss_AE=loss_AE)\n",
    "        # print(loss_AE)\n",
    "\n",
    "    cost = loss_AE / len(dataloader) # average loss 값 계산\n",
    "    print(f'{cost:.6f}')\n",
    "    # if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "        # print(f\"[{epoch + 1}] loss: {cost:.3f}\") # 현재 epoch와 평균 loss 값을 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e456fc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.encoder.state_dict(), \"encoder.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6d34202-0af4-4484-af18-ddb7770734db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (t_fc1): Linear(in_features=9, out_features=64, bias=True)\n",
       "  (t_fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (s_fc1): Linear(in_features=9, out_features=64, bias=True)\n",
       "  (s_fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (p_layers): ModuleList(\n",
       "    (0): SeparableConv1d(\n",
       "      (depthwise): Conv1d(9, 9, kernel_size=(3,), stride=(1,), padding=(1,), groups=9)\n",
       "      (pointwise): Conv1d(9, 64, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (1-6): 6 x SeparableConv1d(\n",
       "      (depthwise): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), groups=64)\n",
       "      (pointwise): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (7): SeparableConv1d(\n",
       "      (depthwise): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), groups=64)\n",
       "      (pointwise): Conv1d(64, 576, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Encoder(window_size=2048).to(device)\n",
    "encoder.load_state_dict(torch.load(\"encoder.pth\"))\n",
    "encoder.eval()\n",
    "# 이후 encoder(x)로 latent feature 추출 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3644b90c-9f54-4025-b130-45892aa039d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 704])\n"
     ]
    }
   ],
   "source": [
    "x, _ = next(iter(dataloader)) # x : (t, p, s)\n",
    "t, p, s = (item.to(device) for item in x)\n",
    "\n",
    "with torch.no_grad():\n",
    "    h = encoder((t, p, s))\n",
    "print(h.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
